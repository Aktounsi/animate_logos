{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surrogate Model\n",
    "### Training of Random Forest, Gradient Boosting, and Extra Trees Classifier wrapped in Ordinal Classifier Framework "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "#import seaborn as sn\n",
    "#import matplotlib.pyplot as plt\n",
    "#import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "#from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from src.preprocessing.transform_into_model_data_ff import *\n",
    "from src.models.ordinal_classifier import *\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib import pyplot\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Set seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds in order to reproduce results\n",
    "random.seed(73)\n",
    "np.random.seed(73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an_vec_0</th>\n",
       "      <th>an_vec_1</th>\n",
       "      <th>an_vec_2</th>\n",
       "      <th>an_vec_3</th>\n",
       "      <th>an_vec_4</th>\n",
       "      <th>an_vec_5</th>\n",
       "      <th>an_vec_6</th>\n",
       "      <th>an_vec_7</th>\n",
       "      <th>an_vec_8</th>\n",
       "      <th>an_vec_9</th>\n",
       "      <th>...</th>\n",
       "      <th>rel_width</th>\n",
       "      <th>rel_x_position</th>\n",
       "      <th>rel_y_position</th>\n",
       "      <th>rel_x_position_to_animations</th>\n",
       "      <th>rel_y_position_to_animations</th>\n",
       "      <th>nr_paths_svg</th>\n",
       "      <th>rating_0</th>\n",
       "      <th>rating_1</th>\n",
       "      <th>rating_2</th>\n",
       "      <th>rating_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054752</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>0.042120</td>\n",
       "      <td>0.039501</td>\n",
       "      <td>0.051404</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395994</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.579289</td>\n",
       "      <td>0.714309</td>\n",
       "      <td>0.706974</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395994</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.637940</td>\n",
       "      <td>0.714309</td>\n",
       "      <td>0.778553</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.134364</td>\n",
       "      <td>0.847434</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054752</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>0.042120</td>\n",
       "      <td>0.039501</td>\n",
       "      <td>0.051404</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.763775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395994</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.579289</td>\n",
       "      <td>0.714309</td>\n",
       "      <td>0.706974</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   an_vec_0  an_vec_1  an_vec_2  an_vec_3  an_vec_4  an_vec_5  an_vec_6  \\\n",
       "0         0         0         0         1         0         0 -1.000000   \n",
       "1         0         0         0         0         0         1 -1.000000   \n",
       "2         0         0         0         0         1         0 -1.000000   \n",
       "3         1         0         0         0         0         0  0.134364   \n",
       "4         0         0         1         0         0         0 -1.000000   \n",
       "\n",
       "   an_vec_7  an_vec_8  an_vec_9  ...  rel_width  rel_x_position  \\\n",
       "0 -1.000000      -1.0 -1.000000  ...   0.054752        0.033838   \n",
       "1 -1.000000      -1.0 -1.000000  ...   0.395994        0.501511   \n",
       "2 -1.000000      -1.0 -1.000000  ...   0.395994        0.501511   \n",
       "3  0.847434      -1.0 -1.000000  ...   0.054752        0.033838   \n",
       "4 -1.000000      -1.0  0.763775  ...   0.395994        0.501511   \n",
       "\n",
       "   rel_y_position  rel_x_position_to_animations  rel_y_position_to_animations  \\\n",
       "0        0.042120                      0.039501                      0.051404   \n",
       "1        0.579289                      0.714309                      0.706974   \n",
       "2        0.637940                      0.714309                      0.778553   \n",
       "3        0.042120                      0.039501                      0.051404   \n",
       "4        0.579289                      0.714309                      0.706974   \n",
       "\n",
       "   nr_paths_svg  rating_0  rating_1  rating_2  rating_3  \n",
       "0          24.0         1         1         1         0  \n",
       "1          24.0         1         1         1         0  \n",
       "2          24.0         1         1         1         0  \n",
       "3          24.0         0         0         0         0  \n",
       "4          24.0         1         1         0         0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = pd.read_csv(\"data/fitness_function/train_ff.csv\")\n",
    "test_dataset = pd.read_csv(\"data/fitness_function/test_ff.csv\") \n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to decode rating labels as orgininal labels are required here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset.iloc[:,:-4]\n",
    "y_train = train_dataset.iloc[:,-4:]\n",
    "y_train = pd.Series(decode_classes(y_train.to_numpy()).flatten())\n",
    "\n",
    "X_test = test_dataset.iloc[:,:-4]\n",
    "y_test = test_dataset.iloc[:,-4:]\n",
    "y_test = pd.Series(decode_classes(y_test.to_numpy()).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an_vec_0</th>\n",
       "      <th>an_vec_1</th>\n",
       "      <th>an_vec_2</th>\n",
       "      <th>an_vec_3</th>\n",
       "      <th>an_vec_4</th>\n",
       "      <th>an_vec_5</th>\n",
       "      <th>an_vec_6</th>\n",
       "      <th>an_vec_7</th>\n",
       "      <th>an_vec_8</th>\n",
       "      <th>an_vec_9</th>\n",
       "      <th>...</th>\n",
       "      <th>diff_fill_r</th>\n",
       "      <th>diff_fill_g</th>\n",
       "      <th>diff_fill_b</th>\n",
       "      <th>rel_height</th>\n",
       "      <th>rel_width</th>\n",
       "      <th>rel_x_position</th>\n",
       "      <th>rel_y_position</th>\n",
       "      <th>rel_x_position_to_animations</th>\n",
       "      <th>rel_y_position_to_animations</th>\n",
       "      <th>nr_paths_svg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.541667</td>\n",
       "      <td>-4.541667</td>\n",
       "      <td>-4.541667</td>\n",
       "      <td>0.084239</td>\n",
       "      <td>0.054752</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>0.042120</td>\n",
       "      <td>0.039501</td>\n",
       "      <td>0.051404</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>0.362888</td>\n",
       "      <td>0.395994</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.579289</td>\n",
       "      <td>0.714309</td>\n",
       "      <td>0.706974</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>0.362904</td>\n",
       "      <td>0.395994</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.637940</td>\n",
       "      <td>0.714309</td>\n",
       "      <td>0.778553</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.134364</td>\n",
       "      <td>0.847434</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.541667</td>\n",
       "      <td>-4.541667</td>\n",
       "      <td>-4.541667</td>\n",
       "      <td>0.084239</td>\n",
       "      <td>0.054752</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>0.042120</td>\n",
       "      <td>0.039501</td>\n",
       "      <td>0.051404</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.763775</td>\n",
       "      <td>...</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>0.362888</td>\n",
       "      <td>0.395994</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.579289</td>\n",
       "      <td>0.714309</td>\n",
       "      <td>0.706974</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   an_vec_0  an_vec_1  an_vec_2  an_vec_3  an_vec_4  an_vec_5  an_vec_6  \\\n",
       "0         0         0         0         1         0         0 -1.000000   \n",
       "1         0         0         0         0         0         1 -1.000000   \n",
       "2         0         0         0         0         1         0 -1.000000   \n",
       "3         1         0         0         0         0         0  0.134364   \n",
       "4         0         0         1         0         0         0 -1.000000   \n",
       "\n",
       "   an_vec_7  an_vec_8  an_vec_9  ...  diff_fill_r  diff_fill_g  diff_fill_b  \\\n",
       "0 -1.000000      -1.0 -1.000000  ...    -4.541667    -4.541667    -4.541667   \n",
       "1 -1.000000      -1.0 -1.000000  ...   102.458333   102.458333   102.458333   \n",
       "2 -1.000000      -1.0 -1.000000  ...   102.458333   102.458333   102.458333   \n",
       "3  0.847434      -1.0 -1.000000  ...    -4.541667    -4.541667    -4.541667   \n",
       "4 -1.000000      -1.0  0.763775  ...   102.458333   102.458333   102.458333   \n",
       "\n",
       "   rel_height  rel_width  rel_x_position  rel_y_position  \\\n",
       "0    0.084239   0.054752        0.033838        0.042120   \n",
       "1    0.362888   0.395994        0.501511        0.579289   \n",
       "2    0.362904   0.395994        0.501511        0.637940   \n",
       "3    0.084239   0.054752        0.033838        0.042120   \n",
       "4    0.362888   0.395994        0.501511        0.579289   \n",
       "\n",
       "   rel_x_position_to_animations  rel_y_position_to_animations  nr_paths_svg  \n",
       "0                      0.039501                      0.051404          24.0  \n",
       "1                      0.714309                      0.706974          24.0  \n",
       "2                      0.714309                      0.778553          24.0  \n",
       "3                      0.039501                      0.051404          24.0  \n",
       "4                      0.714309                      0.706974          24.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    3\n",
       "2    3\n",
       "3    0\n",
       "4    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: upsampling of class 4 to account for imbalanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Grid for Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'log2'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [20, 240, 460, 680, 900, 1120, 1340, 1560, 1780, 2000]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start=20, stop=2000, num=10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=460; total time=  15.9s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=460; total time=  15.9s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=460; total time=  15.3s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=460; total time=  15.6s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=460; total time=  15.5s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=460; total time=  19.6s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=460; total time=  19.9s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=460; total time=  19.1s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=460; total time=  19.5s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=460; total time=  19.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=<src.models.ordinal_classifier.RandomForestOC object at 0x7fe718253fd0>,\n",
       "                   n_iter=3,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [20, 240, 460, 680, 900,\n",
       "                                                         1120, 1340, 1560, 1780,\n",
       "                                                         2000]},\n",
       "                   random_state=42, scoring='neg_mean_absolute_error',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestOC()\n",
    "# Random search of parameters, using 3 fold cross validation, search across 100 different combinations\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 3, cv = 5, verbose=2, random_state=42, scoring = 'neg_mean_absolute_error')\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get best parameters and best evaluation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 460,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 90,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8690855906466378"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train best model on whole training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = rf_random.best_estimator_\n",
    "rf_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate best model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = rf_best.predict(X_test)\n",
    "y_pred_train = rf_best.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label MAE of best random forest classifier on train set: 0.24618572235825956\n",
      "Label MAE of best random forest classifier on test set: 0.8368336025848142\n"
     ]
    }
   ],
   "source": [
    "print(f'Label MAE of best random forest classifier on train set: {mean_absolute_error(y_pred_train, y_train)}')\n",
    "print(f'Label MAE of best random forest classifier on test set: {mean_absolute_error(y_pred_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  best random forest classifier on train set: 0.8372574872857412\n",
      "Accuracy of best random forest classifier on test set: 0.41518578352180935\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy of  best random forest classifier on train set: {accuracy_score(y_pred_train, y_train)}')\n",
    "print(f'Accuracy of best random forest classifier on test set: {accuracy_score(y_pred_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.79      0.65       238\n",
      "           1       0.24      0.15      0.19       205\n",
      "           2       0.36      0.64      0.46       348\n",
      "           3       0.49      0.19      0.28       375\n",
      "           4       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.42      1238\n",
      "   macro avg       0.33      0.35      0.31      1238\n",
      "weighted avg       0.39      0.42      0.37      1238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jani/.conda/envs/animate_logos/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jani/.conda/envs/animate_logos/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jani/.conda/envs/animate_logos/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[187  15  32   4   0]\n",
      " [ 53  31  98  23   0]\n",
      " [ 51  38 223  36   0]\n",
      " [ 43  36 223  73   0]\n",
      " [  4  10  44  14   0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/sm_random_forest.sav'\n",
    "pickle.dump(rf_best, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Grid for Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define meaningful parameter grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=460; total time=  18.3s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=460; total time=  17.4s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=460; total time=  17.6s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=460; total time=  15.9s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=460; total time=  16.3s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=460; total time=  21.7s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=460; total time=  22.0s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=460; total time=  20.8s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=460; total time=  22.7s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=460; total time=  25.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=<src.models.ordinal_classifier.RandomForestOC object at 0x7fe71ffe7f40>,\n",
       "                   n_iter=3,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [20, 240, 460, 680, 900,\n",
       "                                                         1120, 1340, 1560, 1780,\n",
       "                                                         2000]},\n",
       "                   random_state=42, scoring='neg_mean_absolute_error',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "gb = GradientBoostingOC()\n",
    "# Random search of parameters, using 3 fold cross validation, search across 100 different combinations\n",
    "gb_random = RandomizedSearchCV(estimator = gb, param_distributions = random_grid, n_iter = 3, cv = 5, verbose=2, random_state=42, scoring = 'neg_mean_absolute_error')\n",
    "# Fit the random search model\n",
    "gb_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get best parameters and best evaluation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 460,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 90,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8690855906466378"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_random.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train best model on whole training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_best = gb_random.best_estimator_\n",
    "gb_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate best model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = gb_best.predict(X_test)\n",
    "y_pred_train = gb_best.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label MAE of best random forest classifier on train set: 0.24618572235825956\n",
      "Label MAE of best random forest classifier on test set: 0.8368336025848142\n"
     ]
    }
   ],
   "source": [
    "print(f'Label MAE of best gradient boosting classifier on train set: {mean_absolute_error(y_pred_train, y_train)}')\n",
    "print(f'Label MAE of best gradient boosting classifier on test set: {mean_absolute_error(y_pred_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  best random forest classifier on train set: 0.8372574872857412\n",
      "Accuracy of best random forest classifier on test set: 0.41518578352180935\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy of  best gradient boosting classifier on train set: {accuracy_score(y_pred_train, y_train)}')\n",
    "print(f'Accuracy of best gradient boosting classifier on test set: {accuracy_score(y_pred_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.79      0.65       238\n",
      "           1       0.24      0.15      0.19       205\n",
      "           2       0.36      0.64      0.46       348\n",
      "           3       0.49      0.19      0.28       375\n",
      "           4       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.42      1238\n",
      "   macro avg       0.33      0.35      0.31      1238\n",
      "weighted avg       0.39      0.42      0.37      1238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jani/.conda/envs/animate_logos/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jani/.conda/envs/animate_logos/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jani/.conda/envs/animate_logos/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[187  15  32   4   0]\n",
      " [ 53  31  98  23   0]\n",
      " [ 51  38 223  36   0]\n",
      " [ 43  36 223  73   0]\n",
      " [  4  10  44  14   0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/sm_gradient_boosting.sav'\n",
    "pickle.dump(gb_best, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Grid for Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define meaningful parameter grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=460; total time=  15.9s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=460; total time=  15.9s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=460; total time=  15.3s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=460; total time=  15.6s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=460; total time=  15.5s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=460; total time=  19.6s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=460; total time=  19.9s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=460; total time=  19.1s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=460; total time=  19.5s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=460; total time=  19.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=<src.models.ordinal_classifier.RandomForestOC object at 0x7fe718253fd0>,\n",
       "                   n_iter=3,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [20, 240, 460, 680, 900,\n",
       "                                                         1120, 1340, 1560, 1780,\n",
       "                                                         2000]},\n",
       "                   random_state=42, scoring='neg_mean_absolute_error',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "et = ExtraTreesOC()\n",
    "# Random search of parameters, using 3 fold cross validation, search across 100 different combinations\n",
    "et_random = RandomizedSearchCV(estimator = et, param_distributions = random_grid, n_iter = 3, cv = 5, verbose=2, random_state=42, scoring = 'neg_mean_absolute_error')\n",
    "# Fit the random search model\n",
    "et_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get best parameters and best evaluation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 460,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 90,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8690855906466378"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_random.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train best model on whole training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_best = et_random.best_estimator_\n",
    "et_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate best model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = et_best.predict(X_test)\n",
    "y_pred_train = et_best.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label MAE of best random forest classifier on train set: 0.24618572235825956\n",
      "Label MAE of best random forest classifier on test set: 0.8368336025848142\n"
     ]
    }
   ],
   "source": [
    "print(f'Label MAE of best extra trees classifier on train set: {mean_absolute_error(y_pred_train, y_train)}')\n",
    "print(f'Label MAE of best extra trees classifier on test set: {mean_absolute_error(y_pred_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  best random forest classifier on train set: 0.8372574872857412\n",
      "Accuracy of best random forest classifier on test set: 0.41518578352180935\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy of  best extra trees classifier on train set: {accuracy_score(y_pred_train, y_train)}')\n",
    "print(f'Accuracy of best extra trees classifier on test set: {accuracy_score(y_pred_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.79      0.65       238\n",
      "           1       0.24      0.15      0.19       205\n",
      "           2       0.36      0.64      0.46       348\n",
      "           3       0.49      0.19      0.28       375\n",
      "           4       0.00      0.00      0.00        72\n",
      "\n",
      "    accuracy                           0.42      1238\n",
      "   macro avg       0.33      0.35      0.31      1238\n",
      "weighted avg       0.39      0.42      0.37      1238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jani/.conda/envs/animate_logos/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jani/.conda/envs/animate_logos/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jani/.conda/envs/animate_logos/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[187  15  32   4   0]\n",
      " [ 53  31  98  23   0]\n",
      " [ 51  38 223  36   0]\n",
      " [ 43  36 223  73   0]\n",
      " [  4  10  44  14   0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/sm_extra_trees.sav'\n",
    "pickle.dump(et_best, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "animate_logos",
   "language": "python",
   "name": "animate_logos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
