{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surrogate Model\n",
    "### Training of Random Forest, Gradient Boosting, and Extra Trees Classifier wrapped in Ordinal Classifier Framework "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:137: UserWarning: NumPy 1.16.5 or above is required for this version of SciPy (detected version 1.16.1)\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "#import seaborn as sn\n",
    "#import matplotlib.pyplot as plt\n",
    "#import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "#from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from src.preprocessing.sm_label_transformer import *\n",
    "from src.models.ordinal_classifier_scikit import *\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib import pyplot\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Set seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds in order to reproduce results\n",
    "random.seed(73)\n",
    "np.random.seed(73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an_vec_0</th>\n",
       "      <th>an_vec_1</th>\n",
       "      <th>an_vec_2</th>\n",
       "      <th>an_vec_3</th>\n",
       "      <th>an_vec_4</th>\n",
       "      <th>an_vec_5</th>\n",
       "      <th>an_vec_6</th>\n",
       "      <th>an_vec_7</th>\n",
       "      <th>an_vec_8</th>\n",
       "      <th>an_vec_9</th>\n",
       "      <th>...</th>\n",
       "      <th>rel_width</th>\n",
       "      <th>rel_x_position</th>\n",
       "      <th>rel_y_position</th>\n",
       "      <th>rel_x_position_to_animations</th>\n",
       "      <th>rel_y_position_to_animations</th>\n",
       "      <th>nr_paths_svg</th>\n",
       "      <th>rating_0</th>\n",
       "      <th>rating_1</th>\n",
       "      <th>rating_2</th>\n",
       "      <th>rating_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054752</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>0.042120</td>\n",
       "      <td>0.039501</td>\n",
       "      <td>0.051404</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395994</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.579289</td>\n",
       "      <td>0.714309</td>\n",
       "      <td>0.706974</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395994</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.637940</td>\n",
       "      <td>0.714309</td>\n",
       "      <td>0.778553</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.134364</td>\n",
       "      <td>0.847434</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054752</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>0.042120</td>\n",
       "      <td>0.039501</td>\n",
       "      <td>0.051404</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.763775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395994</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.579289</td>\n",
       "      <td>0.714309</td>\n",
       "      <td>0.706974</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   an_vec_0  an_vec_1  an_vec_2  an_vec_3  an_vec_4  an_vec_5  an_vec_6  \\\n",
       "0         0         0         0         1         0         0 -1.000000   \n",
       "1         0         0         0         0         0         1 -1.000000   \n",
       "2         0         0         0         0         1         0 -1.000000   \n",
       "3         1         0         0         0         0         0  0.134364   \n",
       "4         0         0         1         0         0         0 -1.000000   \n",
       "\n",
       "   an_vec_7  an_vec_8  an_vec_9  ...  rel_width  rel_x_position  \\\n",
       "0 -1.000000      -1.0 -1.000000  ...   0.054752        0.033838   \n",
       "1 -1.000000      -1.0 -1.000000  ...   0.395994        0.501511   \n",
       "2 -1.000000      -1.0 -1.000000  ...   0.395994        0.501511   \n",
       "3  0.847434      -1.0 -1.000000  ...   0.054752        0.033838   \n",
       "4 -1.000000      -1.0  0.763775  ...   0.395994        0.501511   \n",
       "\n",
       "   rel_y_position  rel_x_position_to_animations  rel_y_position_to_animations  \\\n",
       "0        0.042120                      0.039501                      0.051404   \n",
       "1        0.579289                      0.714309                      0.706974   \n",
       "2        0.637940                      0.714309                      0.778553   \n",
       "3        0.042120                      0.039501                      0.051404   \n",
       "4        0.579289                      0.714309                      0.706974   \n",
       "\n",
       "   nr_paths_svg  rating_0  rating_1  rating_2  rating_3  \n",
       "0          24.0         1         1         1         0  \n",
       "1          24.0         1         1         1         0  \n",
       "2          24.0         1         1         1         0  \n",
       "3          24.0         0         0         0         0  \n",
       "4          24.0         1         1         0         0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = pd.read_csv(\"data/surrogate_model/sm_train_23042021.csv\")\n",
    "test_dataset = pd.read_csv(\"data/surrogate_model/sm_test_23042021.csv\") \n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to decode rating labels as orgininal labels are required here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset.iloc[:,:-4]\n",
    "y_train = train_dataset.iloc[:,-4:]\n",
    "y_train = pd.Series(decode_classes(y_train.to_numpy()).flatten())\n",
    "\n",
    "X_test = test_dataset.iloc[:,:-4]\n",
    "y_test = test_dataset.iloc[:,-4:]\n",
    "y_test = pd.Series(decode_classes(y_test.to_numpy()).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an_vec_0</th>\n",
       "      <th>an_vec_1</th>\n",
       "      <th>an_vec_2</th>\n",
       "      <th>an_vec_3</th>\n",
       "      <th>an_vec_4</th>\n",
       "      <th>an_vec_5</th>\n",
       "      <th>an_vec_6</th>\n",
       "      <th>an_vec_7</th>\n",
       "      <th>an_vec_8</th>\n",
       "      <th>an_vec_9</th>\n",
       "      <th>...</th>\n",
       "      <th>diff_fill_r</th>\n",
       "      <th>diff_fill_g</th>\n",
       "      <th>diff_fill_b</th>\n",
       "      <th>rel_height</th>\n",
       "      <th>rel_width</th>\n",
       "      <th>rel_x_position</th>\n",
       "      <th>rel_y_position</th>\n",
       "      <th>rel_x_position_to_animations</th>\n",
       "      <th>rel_y_position_to_animations</th>\n",
       "      <th>nr_paths_svg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.541667</td>\n",
       "      <td>-4.541667</td>\n",
       "      <td>-4.541667</td>\n",
       "      <td>0.084239</td>\n",
       "      <td>0.054752</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>0.042120</td>\n",
       "      <td>0.039501</td>\n",
       "      <td>0.051404</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>0.362888</td>\n",
       "      <td>0.395994</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.579289</td>\n",
       "      <td>0.714309</td>\n",
       "      <td>0.706974</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>0.362904</td>\n",
       "      <td>0.395994</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.637940</td>\n",
       "      <td>0.714309</td>\n",
       "      <td>0.778553</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.134364</td>\n",
       "      <td>0.847434</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.541667</td>\n",
       "      <td>-4.541667</td>\n",
       "      <td>-4.541667</td>\n",
       "      <td>0.084239</td>\n",
       "      <td>0.054752</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>0.042120</td>\n",
       "      <td>0.039501</td>\n",
       "      <td>0.051404</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.763775</td>\n",
       "      <td>...</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>0.362888</td>\n",
       "      <td>0.395994</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.579289</td>\n",
       "      <td>0.714309</td>\n",
       "      <td>0.706974</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   an_vec_0  an_vec_1  an_vec_2  an_vec_3  an_vec_4  an_vec_5  an_vec_6  \\\n",
       "0         0         0         0         1         0         0 -1.000000   \n",
       "1         0         0         0         0         0         1 -1.000000   \n",
       "2         0         0         0         0         1         0 -1.000000   \n",
       "3         1         0         0         0         0         0  0.134364   \n",
       "4         0         0         1         0         0         0 -1.000000   \n",
       "\n",
       "   an_vec_7  an_vec_8  an_vec_9  ...  diff_fill_r  diff_fill_g  diff_fill_b  \\\n",
       "0 -1.000000      -1.0 -1.000000  ...    -4.541667    -4.541667    -4.541667   \n",
       "1 -1.000000      -1.0 -1.000000  ...   102.458333   102.458333   102.458333   \n",
       "2 -1.000000      -1.0 -1.000000  ...   102.458333   102.458333   102.458333   \n",
       "3  0.847434      -1.0 -1.000000  ...    -4.541667    -4.541667    -4.541667   \n",
       "4 -1.000000      -1.0  0.763775  ...   102.458333   102.458333   102.458333   \n",
       "\n",
       "   rel_height  rel_width  rel_x_position  rel_y_position  \\\n",
       "0    0.084239   0.054752        0.033838        0.042120   \n",
       "1    0.362888   0.395994        0.501511        0.579289   \n",
       "2    0.362904   0.395994        0.501511        0.637940   \n",
       "3    0.084239   0.054752        0.033838        0.042120   \n",
       "4    0.362888   0.395994        0.501511        0.579289   \n",
       "\n",
       "   rel_x_position_to_animations  rel_y_position_to_animations  nr_paths_svg  \n",
       "0                      0.039501                      0.051404          24.0  \n",
       "1                      0.714309                      0.706974          24.0  \n",
       "2                      0.714309                      0.778553          24.0  \n",
       "3                      0.039501                      0.051404          24.0  \n",
       "4                      0.714309                      0.706974          24.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    3\n",
       "2    3\n",
       "3    0\n",
       "4    2\n",
       "dtype: int32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Upscaling of class 4/\"Very Good\" (optional, was shown to not improve the performance^)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2580, 1: 2143, 2: 3752, 3: 1892, 4: 402}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
    "label_counts = dict(zip(unique_train, counts_train))\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices where data label equals 4\n",
    "i_class4 = np.where(y_train == 4)[0]\n",
    "# Calculate upsample size (mean of class sizes 0-3 - class size 4)\n",
    "upsample_size = round(np.mean([label_counts[i] for i in range(4)])) - label_counts[4]\n",
    "# Get upsample indices\n",
    "i_class4_upsampled = np.random.choice(i_class4, size=upsample_size, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create upsampled dataframe\n",
    "y_train = pd.concat([y_train, y_train[i_class4_upsampled]]).reset_index(drop=True)\n",
    "X_train = pd.concat([X_train, X_train.iloc[i_class4_upsampled,:]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       3\n",
       "2       3\n",
       "3       0\n",
       "4       2\n",
       "       ..\n",
       "6234    4\n",
       "6235    4\n",
       "6236    4\n",
       "6237    4\n",
       "6238    4\n",
       "Length: 6239, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Outlier removal (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an_vec_0</th>\n",
       "      <th>an_vec_1</th>\n",
       "      <th>an_vec_2</th>\n",
       "      <th>an_vec_3</th>\n",
       "      <th>an_vec_4</th>\n",
       "      <th>an_vec_5</th>\n",
       "      <th>an_vec_6</th>\n",
       "      <th>an_vec_7</th>\n",
       "      <th>an_vec_8</th>\n",
       "      <th>an_vec_9</th>\n",
       "      <th>...</th>\n",
       "      <th>diff_fill_g</th>\n",
       "      <th>diff_fill_b</th>\n",
       "      <th>rel_height</th>\n",
       "      <th>rel_width</th>\n",
       "      <th>rel_x_position</th>\n",
       "      <th>rel_y_position</th>\n",
       "      <th>rel_x_position_to_animations</th>\n",
       "      <th>rel_y_position_to_animations</th>\n",
       "      <th>nr_paths_svg</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.541667</td>\n",
       "      <td>-4.541667</td>\n",
       "      <td>0.084239</td>\n",
       "      <td>0.054752</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>0.042120</td>\n",
       "      <td>0.039501</td>\n",
       "      <td>0.051404</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>0.362888</td>\n",
       "      <td>0.395994</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.579289</td>\n",
       "      <td>0.714309</td>\n",
       "      <td>0.706974</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>0.362904</td>\n",
       "      <td>0.395994</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.637940</td>\n",
       "      <td>0.714309</td>\n",
       "      <td>0.778553</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.134364</td>\n",
       "      <td>0.847434</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.541667</td>\n",
       "      <td>-4.541667</td>\n",
       "      <td>0.084239</td>\n",
       "      <td>0.054752</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>0.042120</td>\n",
       "      <td>0.039501</td>\n",
       "      <td>0.051404</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.763775</td>\n",
       "      <td>...</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>102.458333</td>\n",
       "      <td>0.362888</td>\n",
       "      <td>0.395994</td>\n",
       "      <td>0.501511</td>\n",
       "      <td>0.579289</td>\n",
       "      <td>0.714309</td>\n",
       "      <td>0.706974</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   an_vec_0  an_vec_1  an_vec_2  an_vec_3  an_vec_4  an_vec_5  an_vec_6  \\\n",
       "0         0         0         0         1         0         0 -1.000000   \n",
       "1         0         0         0         0         0         1 -1.000000   \n",
       "2         0         0         0         0         1         0 -1.000000   \n",
       "3         1         0         0         0         0         0  0.134364   \n",
       "4         0         0         1         0         0         0 -1.000000   \n",
       "\n",
       "   an_vec_7  an_vec_8  an_vec_9  ...  diff_fill_g  diff_fill_b  rel_height  \\\n",
       "0 -1.000000      -1.0 -1.000000  ...    -4.541667    -4.541667    0.084239   \n",
       "1 -1.000000      -1.0 -1.000000  ...   102.458333   102.458333    0.362888   \n",
       "2 -1.000000      -1.0 -1.000000  ...   102.458333   102.458333    0.362904   \n",
       "3  0.847434      -1.0 -1.000000  ...    -4.541667    -4.541667    0.084239   \n",
       "4 -1.000000      -1.0  0.763775  ...   102.458333   102.458333    0.362888   \n",
       "\n",
       "   rel_width  rel_x_position  rel_y_position  rel_x_position_to_animations  \\\n",
       "0   0.054752        0.033838        0.042120                      0.039501   \n",
       "1   0.395994        0.501511        0.579289                      0.714309   \n",
       "2   0.395994        0.501511        0.637940                      0.714309   \n",
       "3   0.054752        0.033838        0.042120                      0.039501   \n",
       "4   0.395994        0.501511        0.579289                      0.714309   \n",
       "\n",
       "   rel_y_position_to_animations  nr_paths_svg  anomaly  \n",
       "0                      0.051404          24.0        1  \n",
       "1                      0.706974          24.0        1  \n",
       "2                      0.778553          24.0        1  \n",
       "3                      0.051404          24.0       -1  \n",
       "4                      0.706974          24.0        1  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use of Isolation Forest\n",
    "ifo = IsolationForest(random_state=0).fit(X_train)\n",
    "X_train[['anomaly']] = ifo.predict(X_train)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "out_ind = X_train[X_train['anomaly']==-1].index\n",
    "X_train.drop(out_ind, inplace=True, axis=0)\n",
    "y_train.drop(out_ind, inplace=True, axis=0)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "X_train.drop('anomaly', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Grid for Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'log2'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [20, 240, 460, 680, 900, 1120, 1340, 1560, 1780, 2000]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start=20, stop=2000, num=10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   2.0s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   1.9s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   2.0s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   1.9s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   2.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "                   estimator=<src.models.ordinal_classifier_scikit.RandomForestOC object at 0x000001CDEAEA86C8>,\n",
       "                   n_iter=1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [20, 240, 460, 680, 900,\n",
       "                                                         1120, 1340, 1560, 1780,\n",
       "                                                         2000]},\n",
       "                   random_state=42, scoring='neg_mean_absolute_error',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# Define stratified cross validation\n",
    "cross_val = StratifiedKFold(n_splits=5)\n",
    "# First create the base model to tune\n",
    "rf = RandomForestOC()\n",
    "# Random search of parameters, using 3 fold cross validation, search across 100 different combinations\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=1, cv=cross_val, verbose=2, random_state=42, scoring='neg_mean_absolute_error')\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get best parameters and best evaluation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 20,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 50,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8123291074060035"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train best model on whole training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = rf_random.best_estimator_\n",
    "rf_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate best model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = rf_best.predict(X_test)\n",
    "y_pred_train = rf_best.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label MAE of best random forest classifier on train set: 0.41248026743430216\n",
      "Label MAE of best random forest classifier on test set: 0.787363304981774\n"
     ]
    }
   ],
   "source": [
    "print(f'Label MAE of best random forest classifier on train set: {mean_absolute_error(y_pred_train, y_train)}')\n",
    "print(f'Label MAE of best random forest classifier on test set: {mean_absolute_error(y_pred_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  best random forest classifier on train set: 0.7060079858854118\n",
      "Accuracy of best random forest classifier on test set: 0.44552450384771164\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy of  best random forest classifier on train set: {accuracy_score(y_pred_train, y_train)}')\n",
    "print(f'Accuracy of best random forest classifier on test set: {accuracy_score(y_pred_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.75      0.61       498\n",
      "           1       0.19      0.13      0.15       414\n",
      "           2       0.47      0.69      0.56       918\n",
      "           3       0.31      0.07      0.11       532\n",
      "           4       0.00      0.00      0.00       107\n",
      "\n",
      "    accuracy                           0.45      2469\n",
      "   macro avg       0.30      0.33      0.29      2469\n",
      "weighted avg       0.38      0.45      0.38      2469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[374  36  82   4   2]\n",
      " [149  54 193  18   0]\n",
      " [120 115 637  46   0]\n",
      " [ 67  64 366  35   0]\n",
      " [ 16  15  65  11   0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/sm_random_forest.sav'\n",
    "pickle.dump(rf_best, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Grid for Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
      " 'max_depth': range(5, 16, 2),\n",
      " 'max_features': range(7, 20, 2),\n",
      " 'min_samples_leaf': range(30, 71, 10),\n",
      " 'min_samples_split': range(200, 1401, 200),\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
      " 'subsample': [0.6, 0.7, 0.75, 0.8, 0.85, 0.9]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Boosting learning rate\n",
    "learning_rate = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = range(5,16,2)\n",
    "\n",
    "min_samples_split = range(200,1401,200)\n",
    "\n",
    "min_samples_leaf = range(30,71,10)\n",
    "\n",
    "max_features = range(7,20,2)\n",
    "\n",
    "subsample = [0.6,0.7,0.75,0.8,0.85,0.9]\n",
    "\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'learning_rate': learning_rate,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'max_features': max_features,\n",
    "               'subsample': subsample}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.1, max_depth=9, max_features=11, min_samples_leaf=30, min_samples_split=600, n_estimators=1400, subsample=0.75; total time= 1.8min\n",
      "[CV] END learning_rate=0.1, max_depth=9, max_features=11, min_samples_leaf=30, min_samples_split=600, n_estimators=1400, subsample=0.75; total time= 1.9min\n",
      "[CV] END learning_rate=0.1, max_depth=9, max_features=11, min_samples_leaf=30, min_samples_split=600, n_estimators=1400, subsample=0.75; total time= 2.2min\n",
      "[CV] END learning_rate=0.1, max_depth=9, max_features=11, min_samples_leaf=30, min_samples_split=600, n_estimators=1400, subsample=0.75; total time= 2.9min\n",
      "[CV] END learning_rate=0.1, max_depth=9, max_features=11, min_samples_leaf=30, min_samples_split=600, n_estimators=1400, subsample=0.75; total time= 2.8min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "                   estimator=<src.models.ordinal_classifier_scikit.GradientBoostingOC object at 0x000001CDEB1BD888>,\n",
       "                   n_iter=1,\n",
       "                   param_distributions={'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        'max_depth': range(5, 16, 2),\n",
       "                                        'max_features': range(7, 20, 2),\n",
       "                                        'min_samples_leaf': range(30, 71, 10),\n",
       "                                        'min_samples_split': range(200, 1401, 200),\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000],\n",
       "                                        'subsample': [0.6, 0.7, 0.75, 0.8, 0.85,\n",
       "                                                      0.9]},\n",
       "                   random_state=42, scoring='neg_mean_absolute_error',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# Define stratified cross validation\n",
    "cross_val = StratifiedKFold(n_splits=5)\n",
    "# First create the base model to tune\n",
    "gb = GradientBoostingOC()\n",
    "# Random search of parameters, using 3 fold cross validation, search across 100 different combinations\n",
    "gb_random = RandomizedSearchCV(estimator=gb, param_distributions=random_grid, n_iter=1, cv=cross_val, verbose=2, random_state=42, scoring = 'neg_mean_absolute_error')\n",
    "# Fit the random search model\n",
    "gb_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get best parameters and best evaluation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.75,\n",
       " 'n_estimators': 1400,\n",
       " 'min_samples_split': 600,\n",
       " 'min_samples_leaf': 30,\n",
       " 'max_features': 11,\n",
       " 'max_depth': 9,\n",
       " 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.82913453232539"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_random.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train best model on whole training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_best = gb_random.best_estimator_\n",
    "gb_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate best model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = gb_best.predict(X_test)\n",
    "y_pred_train = gb_best.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label MAE of best gradient boosting classifier on train set: 0.22091187668307177\n",
      "Label MAE of best gradient boosting classifier on test set: 0.7825030376670717\n"
     ]
    }
   ],
   "source": [
    "print(f'Label MAE of best gradient boosting classifier on train set: {mean_absolute_error(y_pred_train, y_train)}')\n",
    "print(f'Label MAE of best gradient boosting classifier on test set: {mean_absolute_error(y_pred_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  best gradient boosting classifier on train set: 0.8281177453802582\n",
      "Accuracy of best gradient boosting classifier on test set: 0.43458890238963144\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy of  best gradient boosting classifier on train set: {accuracy_score(y_pred_train, y_train)}')\n",
    "print(f'Accuracy of best gradient boosting classifier on test set: {accuracy_score(y_pred_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.62      0.59       498\n",
      "           1       0.22      0.30      0.25       414\n",
      "           2       0.50      0.59      0.54       918\n",
      "           3       0.38      0.18      0.25       532\n",
      "           4       0.00      0.00      0.00       107\n",
      "\n",
      "    accuracy                           0.43      2469\n",
      "   macro avg       0.33      0.34      0.33      2469\n",
      "weighted avg       0.42      0.43      0.42      2469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[308 110  64  15   1]\n",
      " [103 126 149  36   0]\n",
      " [ 82 201 541  91   3]\n",
      " [ 39 117 276  98   2]\n",
      " [  6  23  59  19   0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/sm_gradient_boosting.sav'\n",
    "pickle.dump(gb_best, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Grid for Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'log2'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [20, 240, 460, 680, 900, 1120, 1340, 1560, 1780, 2000]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start=20, stop=2000, num=10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=20; total time=   0.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "                   estimator=<src.models.ordinal_classifier_scikit.ExtraTreesOC object at 0x000001CDEC4A7208>,\n",
       "                   n_iter=1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [20, 240, 460, 680, 900,\n",
       "                                                         1120, 1340, 1560, 1780,\n",
       "                                                         2000]},\n",
       "                   random_state=42, scoring='neg_mean_absolute_error',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# Define stratified cross validation\n",
    "cross_val = StratifiedKFold(n_splits=5)\n",
    "# First create the base model to tune\n",
    "et = ExtraTreesOC()\n",
    "# Random search of parameters, using 3 fold cross validation, search across 100 different combinations\n",
    "et_random = RandomizedSearchCV(estimator = et, param_distributions = random_grid, n_iter = 1, cv = cross_val, verbose=2, random_state=42, scoring = 'neg_mean_absolute_error')\n",
    "# Fit the random search model\n",
    "et_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get best parameters and best evaluation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 20,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 50,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7962629071050694"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_random.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train best model on whole training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_best = et_random.best_estimator_\n",
    "et_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate best model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = et_best.predict(X_test)\n",
    "y_pred_train = et_best.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label MAE of best extra trees classifier on train set: 0.505896554926177\n",
      "Label MAE of best extra trees classifier on test set: 0.7586067233697853\n"
     ]
    }
   ],
   "source": [
    "print(f'Label MAE of best extra trees classifier on train set: {mean_absolute_error(y_pred_train, y_train)}')\n",
    "print(f'Label MAE of best extra trees classifier on test set: {mean_absolute_error(y_pred_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  best extra trees classifier on train set: 0.6466710000928592\n",
      "Accuracy of best extra trees classifier on test set: 0.46132037262049413\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy of  best extra trees classifier on train set: {accuracy_score(y_pred_train, y_train)}')\n",
    "print(f'Accuracy of best extra trees classifier on test set: {accuracy_score(y_pred_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.75      0.61       498\n",
      "           1       0.23      0.11      0.15       414\n",
      "           2       0.48      0.76      0.59       918\n",
      "           3       0.24      0.04      0.06       532\n",
      "           4       0.00      0.00      0.00       107\n",
      "\n",
      "    accuracy                           0.46      2469\n",
      "   macro avg       0.29      0.33      0.28      2469\n",
      "weighted avg       0.37      0.46      0.38      2469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[374  35  84   5   0]\n",
      " [150  46 206  12   0]\n",
      " [115  63 699  41   0]\n",
      " [ 68  46 398  20   0]\n",
      " [ 17   6  77   7   0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/sm_extra_trees.sav'\n",
    "pickle.dump(et_best, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
